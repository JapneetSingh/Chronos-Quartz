{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from urllib2 import urlopen\n",
    "import urllib\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "import json#for storing beautiful soup to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_db = client['images']\n",
    "image_data = img_db['image_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To get a beautiful soup object\n",
    "def make_soup(url):\n",
    "    \n",
    "    #html = urlopen(url).read()\n",
    "    page = requests.get(url)\n",
    "    html = page.text\n",
    "    return BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the product specification table FROM amazon product page\n",
    "def get_prod_table(soup):\n",
    "    tab = soup.select('table.a-keyvalue.a-spacing-mini')[0] # Because ut returns 1 table in a list\n",
    "    #print tab\n",
    "    table = [] \n",
    "    for tr in tab.findAll('tr'):\n",
    "        try:\n",
    "            table.append(str((tr.th.get_text().strip(),tr.td.get_text().strip())))\n",
    "        except:\n",
    "            pass\n",
    "    return table        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the product description FROM amazon product page\n",
    "def get_prod_desc(soup):\n",
    "    desc = soup.findAll('div',attrs={'id' : 'productDescription'})[0]#all product description are kept like this\n",
    "    return desc.get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the title of the amazon product page\n",
    "def get_prod_title(soup):\n",
    "    title = soup.findAll('span',attrs={'id' : 'productTitle'})[0]\n",
    "    return str(title.get_text().strip())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#INsert data into mongodb\n",
    "\n",
    "def insert_to_mongo(soup,prod_url,img_url,link_counter):\n",
    "    \n",
    "    #Get decription table and product description\n",
    "    table = get_prod_table(soup)\n",
    "    \n",
    "    description = get_prod_desc(soup)\n",
    "    title = get_prod_title(soup)\n",
    "    \n",
    "    image_data.insert_one({ 'img_no' : link_counter,'prod_url':prod_url,'img_url': img_url,\"prod_info_table\":table,\"prod_desc\": description, \"title\" :title  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a link and the number of link creates a folder using number and stores images in it   \n",
    "#Link counter counts each page images are scraped from used to save the images\n",
    "def get_images(prod_url, link_counter):  \n",
    "    \n",
    "    #Make soup with product url\n",
    "    soup = make_soup(prod_url)\n",
    "    \n",
    "    #this makes a list of bs4 element image tags\n",
    "    images = [img for img in soup.select('img.a-dynamic-image.a-stretch-vertical')]\n",
    "    \n",
    "    #print (str(len(images)) + \"images found.\")\n",
    "    #print 'Downloading images to current working directory.'\n",
    "    #compile our unicode list of image links\n",
    "    \n",
    "    image_links = [each['data-old-hires'] for each in images]\n",
    "    \n",
    "    #print image_links\n",
    "    #To standardize the name of each image on prod_url we use file_name as a counter\n",
    "    file_name = 0\n",
    "    \n",
    "    #Create a sub directory for each link and go to that directory\n",
    "    os.mkdir('{0}'.format(link_counter))\n",
    "    os.chdir('{0}'.format(link_counter))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Get images and store them \n",
    "    for each in image_links:\n",
    "        try:\n",
    "            filename='{0}.jpg'.format(link_counter)\n",
    "            #print \"???????????????\", filename\n",
    "            #print each\n",
    "            \n",
    "            urllib.urlretrieve(each, filename)\n",
    "            #Alternative to urlretrieve\n",
    "            #r = requests.get(each)\n",
    "            #with open(filename,'wb') as f:\n",
    "            #f.write(r.content)\n",
    "            file_name  += 1\n",
    "            #insert text to mongodb\n",
    "            insert_to_mongo(soup,prod_url,each,link_counter)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # return to original directory\n",
    "    os.chdir('..')\n",
    "    return image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def lets_scrape_amazon(init_url,no_of_pages, prog_track_interval = 10):\n",
    "\n",
    "    link_counter  = 0\n",
    "\n",
    "    for i in range(1,(no_of_pages+1)):\n",
    "        # Link for wristwatches with rating > 4 stars\n",
    "        url =init_url.format(i,i)\n",
    "        \n",
    "        #Make soup with the search page\n",
    "        soup = make_soup(url)\n",
    "        \n",
    "        #Get the individual links to the product for each search page\n",
    "        links = [link.get('href') for link in soup.select(\"a.a-link-normal.s-access-detail-page\")]\n",
    "        \n",
    "        for link in links:\n",
    "            get_images(link,link_counter)\n",
    "            #Printing to track progress\n",
    "            if (link_counter% prog_track_interval) == 0 :\n",
    "                print \"%d images downloaded\"%(link_counter)\n",
    "            link_counter += 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = requests.get('http://www.amazon.com/Casio-MQ24-1E-Black-Resin-Watch/dp/B000GAWSHM/ref=pd_sim_241_2?ie=UTF8&dpID=41ISNYs3UcL&dpSrc=sims&preST=_AC_UL160_SR86%2C160_&refRID=1AG5VNPHYQX7XQ4KXRPX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup =  BeautifulSoup(x.text,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Code Test\n",
    "\n",
    "link_counter  = 0\n",
    "\n",
    "for i in range(1,100):\n",
    "    # Link for wristwatches with rating > 4 stars\n",
    "    url =\"http://www.amazon.com/s/ref=sr_pg_{0}?fst=as%3Aoff&rh=n%3A7141123011%2Cn%3A10445813011%2Cn%3A7147441011%2Cn%3A6358539011%2Cn%3A6358540011%2Ck%3Awrist+watches%2Cp_72%3A2661618011&page={1}&bbn=10445813011&keywords=wrist+watches&ie=UTF8&qid=1451726453\".format(i,i)\n",
    "    soup = make_soup(url)\n",
    "    links = [link.get('href') for link in soup.select(\"a.a-link-normal.s-access-detail-page\")]\n",
    "    link_counter +=1\n",
    "    for link in links:\n",
    "        print \">>>>>>%s>>>>>\"%link_counter,link\n",
    "        \n",
    "    #img_urls = [] Can be used to save urls. We can also get titles fr each of the images describing what they are\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_search_url = \"http://www.amazon.com/s/ref=sr_pg_{0}?fst=as%3Aoff&rh=n%3A7141123011%2Cn%3A10445813011%2Cn%3A7147441011%2Cn%3A6358539011%2Cn%3A6358540011%2Ck%3Awrist+watches%2Cp_72%3A2661618011&page={1}&bbn=10445813011&keywords=wrist+watches&ie=UTF8&qid=1451726453\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images downloaded\n",
      "20 images downloaded\n",
      "40 images downloaded\n",
      "60 images downloaded\n",
      "80 images downloaded\n",
      "100 images downloaded\n",
      "120 images downloaded\n",
      "140 images downloaded\n",
      "160 images downloaded\n",
      "180 images downloaded\n",
      "200 images downloaded\n",
      "220 images downloaded\n",
      "240 images downloaded\n",
      "260 images downloaded\n",
      "280 images downloaded\n",
      "300 images downloaded\n",
      "320 images downloaded\n",
      "340 images downloaded\n",
      "360 images downloaded\n",
      "380 images downloaded\n",
      "400 images downloaded\n",
      "420 images downloaded\n",
      "440 images downloaded\n",
      "460 images downloaded\n",
      "480 images downloaded\n",
      "500 images downloaded\n",
      "520 images downloaded\n",
      "540 images downloaded\n",
      "560 images downloaded\n",
      "580 images downloaded\n",
      "600 images downloaded\n",
      "620 images downloaded\n",
      "640 images downloaded\n",
      "660 images downloaded\n",
      "680 images downloaded\n",
      "700 images downloaded\n",
      "720 images downloaded\n",
      "740 images downloaded\n",
      "760 images downloaded\n",
      "780 images downloaded\n",
      "800 images downloaded\n",
      "820 images downloaded\n",
      "840 images downloaded\n",
      "860 images downloaded\n",
      "880 images downloaded\n",
      "900 images downloaded\n",
      "920 images downloaded\n",
      "940 images downloaded\n",
      "960 images downloaded\n",
      "980 images downloaded\n",
      "1000 images downloaded\n",
      "1020 images downloaded\n",
      "1040 images downloaded\n",
      "1060 images downloaded\n",
      "1080 images downloaded\n",
      "1100 images downloaded\n",
      "1120 images downloaded\n",
      "1140 images downloaded\n",
      "1160 images downloaded\n",
      "1180 images downloaded\n",
      "1200 images downloaded\n",
      "1220 images downloaded\n",
      "1240 images downloaded\n",
      "1260 images downloaded\n",
      "1280 images downloaded\n",
      "1300 images downloaded\n",
      "1320 images downloaded\n",
      "1340 images downloaded\n",
      "1360 images downloaded\n",
      "1380 images downloaded\n",
      "1400 images downloaded\n",
      "1420 images downloaded\n",
      "1440 images downloaded\n",
      "1460 images downloaded\n",
      "1480 images downloaded\n",
      "1500 images downloaded\n",
      "1520 images downloaded\n",
      "1540 images downloaded\n",
      "1560 images downloaded\n",
      "1580 images downloaded\n",
      "1600 images downloaded\n",
      "1620 images downloaded\n",
      "1640 images downloaded\n",
      "1660 images downloaded\n",
      "1680 images downloaded\n",
      "1700 images downloaded\n",
      "1720 images downloaded\n",
      "1740 images downloaded\n",
      "1760 images downloaded\n",
      "1780 images downloaded\n",
      "1800 images downloaded\n",
      "1820 images downloaded\n",
      "1840 images downloaded\n",
      "1860 images downloaded\n",
      "1880 images downloaded\n",
      "1900 images downloaded\n",
      "1920 images downloaded\n",
      "1940 images downloaded\n",
      "1960 images downloaded\n",
      "1980 images downloaded\n",
      "2000 images downloaded\n",
      "2020 images downloaded\n",
      "2040 images downloaded\n",
      "2060 images downloaded\n",
      "2080 images downloaded\n",
      "2100 images downloaded\n",
      "2120 images downloaded\n",
      "2140 images downloaded\n",
      "2160 images downloaded\n",
      "2180 images downloaded\n",
      "2200 images downloaded\n",
      "2220 images downloaded\n",
      "2240 images downloaded\n",
      "2260 images downloaded\n",
      "2280 images downloaded\n",
      "2300 images downloaded\n",
      "2320 images downloaded\n",
      "2340 images downloaded\n",
      "2360 images downloaded\n",
      "2380 images downloaded\n",
      "2400 images downloaded\n",
      "2420 images downloaded\n",
      "2440 images downloaded\n",
      "2460 images downloaded\n",
      "2480 images downloaded\n",
      "2500 images downloaded\n",
      "2520 images downloaded\n",
      "2540 images downloaded\n",
      "2560 images downloaded\n",
      "2580 images downloaded\n",
      "2600 images downloaded\n",
      "2620 images downloaded\n",
      "2640 images downloaded\n",
      "2660 images downloaded\n",
      "2680 images downloaded\n",
      "2700 images downloaded\n",
      "2720 images downloaded\n",
      "2740 images downloaded\n",
      "2760 images downloaded\n",
      "2780 images downloaded\n",
      "2800 images downloaded\n",
      "2820 images downloaded\n",
      "2840 images downloaded\n",
      "2860 images downloaded\n",
      "2880 images downloaded\n",
      "2900 images downloaded\n",
      "2920 images downloaded\n",
      "2940 images downloaded\n",
      "2960 images downloaded\n",
      "2980 images downloaded\n",
      "3000 images downloaded\n",
      "3020 images downloaded\n",
      "3040 images downloaded\n",
      "3060 images downloaded\n",
      "3080 images downloaded\n",
      "3100 images downloaded\n",
      "3120 images downloaded\n",
      "3140 images downloaded\n",
      "3160 images downloaded\n",
      "3180 images downloaded\n",
      "3200 images downloaded\n",
      "3220 images downloaded\n",
      "3240 images downloaded\n",
      "3260 images downloaded\n",
      "3280 images downloaded\n",
      "3300 images downloaded\n",
      "3320 images downloaded\n",
      "3340 images downloaded\n",
      "3360 images downloaded\n",
      "3380 images downloaded\n",
      "3400 images downloaded\n",
      "3420 images downloaded\n",
      "3440 images downloaded\n",
      "3460 images downloaded\n",
      "3480 images downloaded\n",
      "3500 images downloaded\n",
      "3520 images downloaded\n",
      "3540 images downloaded\n",
      "3560 images downloaded\n",
      "3580 images downloaded\n",
      "3600 images downloaded\n",
      "3620 images downloaded\n",
      "3640 images downloaded\n",
      "3660 images downloaded\n",
      "3680 images downloaded\n",
      "3700 images downloaded\n",
      "3720 images downloaded\n",
      "3740 images downloaded\n",
      "3760 images downloaded\n",
      "3780 images downloaded\n",
      "3800 images downloaded\n",
      "3820 images downloaded\n",
      "3840 images downloaded\n",
      "3860 images downloaded\n",
      "3880 images downloaded\n",
      "3900 images downloaded\n",
      "3920 images downloaded\n",
      "3940 images downloaded\n",
      "3960 images downloaded\n",
      "3980 images downloaded\n",
      "4000 images downloaded\n",
      "4020 images downloaded\n",
      "4040 images downloaded\n",
      "4060 images downloaded\n",
      "4080 images downloaded\n",
      "4100 images downloaded\n",
      "4120 images downloaded\n",
      "4140 images downloaded\n",
      "4160 images downloaded\n",
      "4180 images downloaded\n",
      "4200 images downloaded\n",
      "4220 images downloaded\n",
      "4240 images downloaded\n",
      "4260 images downloaded\n",
      "4280 images downloaded\n",
      "4300 images downloaded\n",
      "4320 images downloaded\n",
      "4340 images downloaded\n",
      "4360 images downloaded\n",
      "4380 images downloaded\n",
      "4400 images downloaded\n",
      "4420 images downloaded\n",
      "4440 images downloaded\n",
      "4460 images downloaded\n",
      "4480 images downloaded\n",
      "4500 images downloaded\n",
      "4520 images downloaded\n",
      "4540 images downloaded\n",
      "4560 images downloaded\n",
      "4580 images downloaded\n",
      "4600 images downloaded\n",
      "4620 images downloaded\n",
      "4640 images downloaded\n",
      "4660 images downloaded\n",
      "4680 images downloaded\n",
      "4700 images downloaded\n",
      "4720 images downloaded\n",
      "4740 images downloaded\n",
      "4760 images downloaded\n",
      "4780 images downloaded\n",
      "4800 images downloaded\n",
      "4820 images downloaded\n",
      "4840 images downloaded\n",
      "4860 images downloaded\n",
      "4880 images downloaded\n",
      "4900 images downloaded\n",
      "4920 images downloaded\n",
      "4940 images downloaded\n",
      "4960 images downloaded\n",
      "4980 images downloaded\n",
      "5000 images downloaded\n",
      "5020 images downloaded\n",
      "5040 images downloaded\n",
      "5060 images downloaded\n",
      "5080 images downloaded\n",
      "5100 images downloaded\n",
      "5120 images downloaded\n",
      "5140 images downloaded\n",
      "5160 images downloaded\n",
      "5180 images downloaded\n",
      "5200 images downloaded\n",
      "5220 images downloaded\n",
      "5240 images downloaded\n",
      "5260 images downloaded\n",
      "5280 images downloaded\n",
      "5300 images downloaded\n",
      "5320 images downloaded\n",
      "5340 images downloaded\n",
      "5360 images downloaded\n",
      "5380 images downloaded\n",
      "5400 images downloaded\n",
      "5420 images downloaded\n",
      "5440 images downloaded\n",
      "5460 images downloaded\n",
      "5480 images downloaded\n",
      "5500 images downloaded\n"
     ]
    }
   ],
   "source": [
    "lets_scrape_amazon(watch_search_url,100,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/.Trash/5 1.47.11 AM/1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
